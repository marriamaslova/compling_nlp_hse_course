{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marriamaslova/compling_nlp_hse_course/blob/master/notebooks/instruct_fine_tuning/homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 10. Генерация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f21d5e",
      "metadata": {
        "id": "76f21d5e"
      },
      "source": [
        "### Задание 1 (10 баллов).\n",
        "\n",
        "В семинаре мы работали с датасетом инструкций alpaca. Он англоязычный. В домашке вам нужно придумать способ создать аналогичный датасет на русском языке и обучить аналогичную модель на этом датасете. \n",
        "В качестве итогового результата у вас должна получится модель, которая может связано отвечать на русскоязычные инструкции на русском языке. Приведите как минимум три разных примера. Правильность ответов не так важно, так как вы скорее всего будете использовать небольшие модели, но текст должен быть не рандомным.\n",
        "\n",
        "Русскоязычный датасет инструкций должен быть больше 5 тысяч примеров. Он может быть основнован на alpaca (например, вы можете просто прогнать все через какую-нибудь переводную модель на huggingface или даже google translate). Или вы можете придумать способ создать аналогичный датасет каким-то другим способом (переделать открытые датасеты с помощью правил). Датасет может быть не уникальным, можно скооперироваться с одногруппниками и сделать один датасет на всех.\n",
        "\n",
        "Вы можете попробовать дообучать любую небольшую decoder-only модель. Скорее всего лучше всего будут работать модели, изначально обученные на русском языке (rugpt например). Но возможно даже модели вроде opt можно будет дообучить на русскоязычных инструкциях.\n",
        "\n",
        "Это задание гораздно менее определенное, по сравнению с предыдущими. Поэтому не стесняйтесь задавать дополнительные вопросы в чате или лично, если у вас возникнут трудности.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas transformers tokenizers datasets xformers"
      ],
      "metadata": {
        "id": "s0obVSsJpe5h"
      },
      "id": "s0obVSsJpe5h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "HtAYC_PVsKeQ"
      },
      "id": "HtAYC_PVsKeQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2444e3fe",
      "metadata": {
        "id": "2444e3fe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import logging\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional, Dict, Sequence\n",
        "import json\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import Trainer\n",
        "import sentencepiece\n",
        "import sacremoses\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "okjQwlQDquWJ"
      },
      "id": "okjQwlQDquWJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07bd89b",
      "metadata": {
        "id": "f07bd89b"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import FSMTForConditionalGeneration, FSMTTokenizer"
      ],
      "metadata": {
        "id": "_0AxIlSEtT7t"
      },
      "id": "_0AxIlSEtT7t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перевод инструкций на русский язык (по факту, для лучшего контроля за процессом я разделила большой файл с инструкциями и переводила по частям, а в конце соединила результаты)"
      ],
      "metadata": {
        "id": "Q6PFEuOzrBrw"
      },
      "id": "Q6PFEuOzrBrw"
    },
    {
      "cell_type": "code",
      "source": [
        "tr_model_name = \"Helsinki-NLP/opus-mt-en-ru\" "
      ],
      "metadata": {
        "id": "8vQ6-LOL19bp"
      },
      "id": "8vQ6-LOL19bp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_tokenizer = AutoTokenizer.from_pretrained(tr_model_name)\n",
        "tr_model = AutoModelForSeq2SeqLM.from_pretrained(tr_model_name) "
      ],
      "metadata": {
        "id": "T8FR8ya119Vr"
      },
      "id": "T8FR8ya119Vr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/alpaca_cut_data.json', 'r') as alpaca_file:\n",
        "  data = json.load(alpaca_file)"
      ],
      "metadata": {
        "id": "MU-Slc7Y19S-"
      },
      "id": "MU-Slc7Y19S-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translation(inp):\n",
        "  input_ids = tr_tokenizer(inp, return_tensors=\"pt\").input_ids\n",
        "  outputs = tr_model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=1)\n",
        "  value_new = ''.join(tr_tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
        "  return value_new"
      ],
      "metadata": {
        "id": "WtN7tkZQFaiZ"
      },
      "id": "WtN7tkZQFaiZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instuctions = []\n",
        "for elem in data:\n",
        "  for key, value in elem.items():\n",
        "    if key == 'instruction':\n",
        "      if value != '':\n",
        "        inp = value\n",
        "        value_inst = translation(inp)\n",
        "      else:\n",
        "        value_inst = ''\n",
        "    if key == 'input':\n",
        "      if value != '':\n",
        "        inp = value\n",
        "        value_inp = translation(inp)\n",
        "      else:\n",
        "        value_inp = ''\n",
        "    if key == 'output':\n",
        "      if value != '':\n",
        "        inp = value\n",
        "        value_out = translation(inp)\n",
        "      else:\n",
        "        value_out = ''\n",
        "  elem['instruction'] = value_inst\n",
        "  elem['input'] = value_inp\n",
        "  elem['output'] = value_out\n",
        "  instuctions.append(elem)"
      ],
      "metadata": {
        "id": "iLLdrUJa19Ql"
      },
      "id": "iLLdrUJa19Ql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('alpaca_cut_rus.json', 'w') as alpaca_file_rus:\n",
        "  json.dump(instuctions, alpaca_file_rus)"
      ],
      "metadata": {
        "id": "VGMRgrN319OH"
      },
      "id": "VGMRgrN319OH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение на инструкциях"
      ],
      "metadata": {
        "id": "iKf4srUd4Tnf"
      },
      "id": "iKf4srUd4Tnf"
    },
    {
      "cell_type": "code",
      "source": [
        "data_alpaca = json.load(open('alpaca_cut_rus.json'))"
      ],
      "metadata": {
        "id": "PC4DGAQL19Lg"
      },
      "id": "PC4DGAQL19Lg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_alpaca[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH6QX7IUNN_J",
        "outputId": "285a5583-7e5a-459c-ae6e-6eaa202190ab"
      },
      "id": "VH6QX7IUNN_J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'instruction': 'Дай три чаевых за то, чтобы оставаться здоровой.',\n",
              "  'input': '',\n",
              "  'output': '2. Регулярное упражнение, с тем чтобы ваше тело было активным и сильным. 3. Успокойтесь и сохраняйте постоянный график сна.'},\n",
              " {'instruction': 'Какие три основных цвета?',\n",
              "  'input': '',\n",
              "  'output': 'Три основных цвета красные, синие и желтые.'},\n",
              " {'instruction': 'Опишите структуру атома.',\n",
              "  'input': '',\n",
              "  'output': 'Атом состоит из ядра, содержащего протоны и нейтроны, окруженного электронами, перемещающимися по орбитам вокруг ядра. Протоны и нейтроны имеют положительный заряд, в то время как электроны имеют отрицательный заряд, что приводит к общему нейтральному атому. Количество частиц определяет атомное число и тип атома.'},\n",
              " {'instruction': 'Как мы можем уменьшить загрязнение воздуха?',\n",
              "  'input': '',\n",
              "  'output': 'Кроме того, отдельные лица могут внести свой вклад в сокращение загрязнения воздуха путем сокращения использования легковых автомобилей, предотвращения сжигания таких материалов, как древесина, и перехода на энергоэффективные приборы.'},\n",
              " {'instruction': 'Опишите время, когда вам пришлось принять трудное решение.',\n",
              "  'input': '',\n",
              "  'output': 'Мне пришлось принять трудное решение, когда я работал руководителем проекта в строительной компании. Я отвечал за проект, который должен был быть завершен к определенному сроку для того, чтобы удовлетворить ожидания клиентов. Однако из-за неожиданных задержек мы не смогли уложиться в сроки, и поэтому мне пришлось принять трудное решение. Я решил продлить срок, но мне пришлось еще больше увеличить ресурсы группы и увеличить бюджет. Хотя это было рискованным решением, я в конечном итоге решил продолжить его, чтобы обеспечить своевременное завершение проекта и выполнение ожиданий клиента. Проект был в конечном итоге успешно завершен, и это рассматривалось как свидетельство моих лидерских и директивных способностей.'},\n",
              " {'instruction': 'Идентифицируйте странного.',\n",
              "  'input': 'Twitter, Instagram, Telegram',\n",
              "  'output': 'Телеграмма'},\n",
              " {'instruction': 'Объясните, почему следующая доля эквивалентна 1/4',\n",
              "  'input': '4/16',\n",
              "  'output': 'Долина 4/16 эквивалентна 1/4, поскольку как числители, так и знаменатели делятся на 4.'},\n",
              " {'instruction': 'Напишите короткую историю на третьем лице, рассказав о герое, который должен принять важное решение о карьере.',\n",
              "  'input': '',\n",
              "  'output': 'Джон был на перепутье в своей жизни. Он только что закончил колледж и в настоящее время столкнулся с большим решением о том, какую карьеру он должен продолжать. После долгих обсуждений он решил, что хочет быть бухгалтером и помогать людям, находящимся в неблагоприятном финансовом положении. Он всегда был хорош в цифрах и наслаждался ощутимыми результатами своей работы. Джон записался на курсы бухгалтерского учета и сначала нашел это довольно сложным. Он должен был быстро научиться нескольким системам и правилам, но он работал усердно и в конечном итоге преуспел в учебе. Через несколько лет Джон начал работать в бухгалтерской фирме в своем городе. Он хотел, чтобы его знания о налогах и бухгалтерском учете использовались в реальном мире. Джон любил свою работу, так как это позволяло ему проявлять творческий подход к поиску стратегий спасения денег своих клиентов. После нескольких лет работы в фирме он стал старшим бухгалтером и был призван заниматься более крупными и сложными делами. Теперь он был уважаемой фигурой в финансовой индустрии, но он все еще помнит, когда он был всего лишь недавно выпускником колледжа, не подозревая о том, в каком направлении его жизнь.'},\n",
              " {'instruction': 'Оформить 3D модель дома',\n",
              "  'input': '',\n",
              "  'output': 'Этот тип инструкции не может быть выполнен с помощью модели GPT.'},\n",
              " {'instruction': 'Оценить это предложение с точки зрения орфографических и грамматических ошибок',\n",
              "  'input': 'Он финнирует свою еду и уезжает из ресторана.',\n",
              "  'output': 'Он закончил ужин и ушел из ресторана.'},\n",
              " {'instruction': 'Как умер Юлий Цезарь?',\n",
              "  'input': '',\n",
              "  'output': 'Юлий Цезарь был убит группой в составе до 60 заговорщиков, возглавляемой Гаюсом Кассиусом Лонгинусом и Марком Джуниусом Брутусом, в Сенате на Иде (15 марта) 44 года до н. э.'},\n",
              " {'instruction': 'Какая столица Франции?',\n",
              "  'input': '',\n",
              "  'output': 'Столица Франции - Париж.'},\n",
              " {'instruction': 'Составьте список из десяти предметов, которые могут понадобиться человеку для поездки в поход.',\n",
              "  'input': '',\n",
              "  'output': '2. Спальные мешки 3. Фонарик 4. Спички/легкий огонь 5. Отталкиваемость насекомыми 6. Дополнительная одежда 7. Аптечка первой помощи 8. Камповая плита 9. Кухонная утварь 10. Биоразлагаемое мыло/шампус'},\n",
              " {'instruction': 'Обсудим причины великой депрессии',\n",
              "  'input': '',\n",
              "  'output': 'Великая депрессия была серьезным глобальным экономическим спадом, который длился с 1929 по 1939 год и был вызван рядом факторов, включая крах фондового рынка в 1929 году, структурные недостатки в экономике, низкие потребительские расходы, высокий уровень безработицы и отсутствие доверия к банковской системе.'},\n",
              " {'instruction': 'Классифицировать следующие категории: животные, растения и минералы.',\n",
              "  'input': 'Оковое дерево, медная руда, слон',\n",
              "  'output': 'Огурцовое дерево: растительная медная руда: минеральное слое: животное'},\n",
              " {'instruction': 'Объясните использование слов, встроенных в естественную языковую обработку',\n",
              "  'input': '',\n",
              "  'output': 'Встраивание слов является одним из наиболее мощных инструментов для естественной языковой обработки (NLP). Это математические изображения слов или фраз в векторном пространстве, позволяющие совпадать между словами и контекстом, в котором они используются для измерения. Встраивание слов полезно для выполнения таких задач, как анализ настроений, текстовая классификация, прогнозирование следующего слова в последовательности и понимание синонимов и аналогий. Они позволяют обрабатывать слова как числовые значения, давая машинам более простой способ выполнения задач NLP.'},\n",
              " {'instruction': 'Опишите функцию компьютерной материнской доски',\n",
              "  'input': '',\n",
              "  'output': 'Компьютерная материнская доска является главной системой в компьютере. Она является основой системы, соединяющей все другие компоненты, такие, как процессор, RAM, хранение, графическая карта и периферийные порты. Она обеспечивает каналы связи между всеми этими компонентами, позволяя им взаимодействовать и работать вместе. Эта доска отвечает за регулирование мощности, а также располагает слотами для расширения карт, а также портами для USB, аудио, Ethernet и других типов подключения.'},\n",
              " {'instruction': 'Обратный проектирование этого кода для создания новой версии',\n",
              "  'input': 'def факториализация (нумерация): факториал = 1 для i в диапазоне(1, нум): факториал * = i возвратный факториал',\n",
              "  'output': 'def факториализация (нумерация): факториал = 1 для i в диапазоне (нумерация, 0, -1): факториал * = i возвратный факториал'},\n",
              " {'instruction': 'Предложение этического решения проблемы конфиденциальности данных',\n",
              "  'input': '',\n",
              "  'output': 'Это означает, что компании не могут осуществлять сбор и использование личных данных без прямого разрешения владельцев данных. Этот подход дает пользователям возможность определять, какие компании могут использовать данные и для каких целей. Компании также должны быть транспарентными в отношении того, как они используют собранные данные, с тем чтобы пользователи могли принимать обоснованные решения и контролировать свои собственные данные.'},\n",
              " {'instruction': 'Создать три глагола, которые означают то же, что и \"извиниться\"',\n",
              "  'input': '',\n",
              "  'output': 'Признать, выразить сожаление, загладить вину.'},\n",
              " {'instruction': 'Что означает ДНК?',\n",
              "  'input': '',\n",
              "  'output': 'ДНК означает дезоксирибонуклеиновую кислоту.'},\n",
              " {'instruction': 'Сравните и контрастируйте с кубинским ракетным кризисом и Вьетнамской войной.',\n",
              "  'input': '',\n",
              "  'output': 'Кубинский ракетный кризис был связан с противостоянием между Соединенными Штатами и Советским Союзом над советскими ядерными ракетными базами на Кубе, в то время как Вьетнамская война была продолжительным военным конфликтом в Индокитае между Севером, который поддерживался Советским Союзом и Югом и который поддерживался Соединенными Штатами. Кубинский ракетный кризис разразился в течение 13 дней в октябре 1962 года с принятием резолюции в форме дипломатического соглашения. Вьетнамская война продолжалась 19 лет, начиная с 1954 года и заканчиваясь в 1973 году, с подписанием Парижских мирных соглашений. Хотя оба эти конфликта были связаны с холодной войной, они также имели весьма различный характер с точки зрения причин, целей, стратегических целей и исходов. Кубинский ракетный кризис не привел к какому-либо прямому военному конфликту и был урегулирован главным образом с помощью дипломатии и решения о выводе ядерного оружия с Кубы. С другой стороны, Вьетнамская война представляла собой длительную серию военных действий, приведших к значительным потерям для обеих сторон. Вьетнамская война также оказала значительное воздействие на Соединенные Штаты, поскольку она высветила реальность затяжного военного конфликта, а также резко изменила сферу применения военной силы США.'},\n",
              " {'instruction': 'Составьте список случайных слов.',\n",
              "  'input': '',\n",
              "  'output': 'чихание, конфликт, предок, гром, компаньон, амулет, подделка, змея, восхитительные, шутки, каскад, вселенная, волна, тошнота, оазис, аномалия, преследование, возвышение, пагода, мозаика.'},\n",
              " {'instruction': 'Перепишите запись в текст.',\n",
              "  'input': 'Запись истории Ватерлоо',\n",
              "  'output': 'Битва при Ватерлоо, сражавшаяся 18 июня 1815 года, была последней крупной битвой наполеоновских войн. Она ознаменовала собой конец правления Наполеона Бонапарта. Битва была сражена между французскими войсками Наполеона Бонапарта и союзниками британских, голландских, бельгийских и прусских войск во главе с герцогом Веллингтонским. Битва была сражалась вблизи города Ватерлоо в бывшем Австрийском Нидерландах, в настоящее время в Бельгии. Сражение было поражением сил Наполеона и положило конец правлению Наполеона над Францией. Наполеон сам был изгнан на остров Св. Елены, где он погиб в 1821 году. Сражение ознаменовало окончание французского господства в Европе и начало периода мира в регионе. Это было последнее крупное сражение наполеоновских сил и воспоминалось как одно из самых важных сражений в истории. Победа союзных сил в Ватоло помогла положить конец французским имперским амбициям в Европе. Он также установил, что английская армия сражила сегодня с одной из самых могущеных стран Европы.'},\n",
              " {'instruction': 'Кто самый известный художник в мире?',\n",
              "  'input': '',\n",
              "  'output': 'Самый известный художник в мире, как правило, считается итальянским художником возрождения Леонардо да Винчи. Его работа включает Mona Lisa и The Last Supper, которые считаются шедевры. Da Vinci также был мастером науки, изобретая вертолёт и танк, среди прочих изобретений. Он также был восхитительным музыкантом, скульптором и архитектором. Его работа вдохновляла поколения художников и продолжает почитаться сегодня.'},\n",
              " {'instruction': 'Объясните концепцию крутящего момента.',\n",
              "  'input': '',\n",
              "  'output': 'Крутящий момент нажима - это крутящий момент, прилагаемый к вращающемуся устройству, когда устройство сталкивается с сопротивлением зубов передач, соединенных с устройством. Крутящий момент нажима происходит из-за силы реакции, создаваемой при нажатии зубов передачи на сетку. Это усилие нажимается друг на друга, что приводит к перетаскиванию от передач к валу. Значения крутящего момента могут варьироваться в зависимости от размера и количества зубов, а также материала и конструкции этой передачи. Крутящий момент нажима является нежелательным в большинстве случаев, когда он может привести к снижению эффективности. Для уменьшения крутящего момента нажима передач конструкция передач часто является симметричной или имеет определенные зубные профили, которые уменьшают силу контакта между зубами, когда они вступают в контакт друг с другом.'},\n",
              " {'instruction': 'Посмотри на точку кипения воды.',\n",
              "  'input': '',\n",
              "  'output': 'Температура кипения воды составляет 100°C (212°F) при стандартном атмосферном давлении. При нагревании при более высоком давлении увеличивается температура кипения воды. Например, вода кипит при температуре 115°C (239°F) при атмосферном давлении 1 бар. При более высоком давлении, как, например, на дне океана, температура кипения воды может достигать 374°C (705°F).'},\n",
              " {'instruction': 'Опишите жизнь и правление короля Карла II.',\n",
              "  'input': '',\n",
              "  'output': 'Король Карл II поднялся на трон Англии после английской гражданской войны и смерти своего отца, Чарльза I. Он был коронован в 1661 году, и его правление продолжалось до его смерти в 1685 году. Карл II был покровителем искусства, работая с некоторыми из величайших художников и скульпторов своего времени. Он также поощрял театр и спорт и был заинтересован в таких науках, как астрономия и естественная история. Чарльз II был умеренным правителем, который уважал гражданские и религиозные свободы своих граждан. Он терпимо относился к другим религиям и давал евреям и католикам больше прав в королевстве. Чарльз II также был сильным сторонником Королевского флота, который видел, как Англия увеличила свою власть в мире. Он также способствовал развитию промышленности и торговли, что способствовало модернизации страны.'},\n",
              " {'instruction': 'Найдите площадь круга с учетом его радиуса.',\n",
              "  'input': 'Радиус = 4',\n",
              "  'output': 'Площадь окружности с радиусом 4 равняется 12,5664 квадратным единицам. Эта площадь рассчитывается по формуле A = Δr2, где A - площадь, Δ - примерно 3,1416, а r - радиус окружности.'},\n",
              " {'instruction': 'Определите линии долготы, разделяющие Северную и Южную Америку.',\n",
              "  'input': '',\n",
              "  'output': 'Границы долготы, разделяющие Северную и Южную Америку, являются линией Панамского канала. Эта линия долготы проходит через перешейк Панамы и отделяет Южную Америку от Центральной Америки. Она составляет приблизительно 800 км (500 мi) общей протяженностью и была завершена в 1914 году. Панамский канал является важным судоходным маршрутом и служит международным водным путем, соединяющим Карибское море с Тихим океаном.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"Below is an instruction that describes a task. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "Mu6GoChnL8YC"
      },
      "id": "Mu6GoChnL8YC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
        "    \"\"\"Tokenize a list of strings.\"\"\"\n",
        "    tokenized_list = [\n",
        "        tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            # padding=\"max_length\",\n",
        "            max_length=tokenizer.model_max_length,\n",
        "            truncation=True,\n",
        "          \n",
        "        )\n",
        "        for text in strings\n",
        "    ]\n",
        "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
        "    input_ids_lens = labels_lens = [\n",
        "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
        "    ]\n",
        "    return dict(\n",
        "        input_ids=input_ids,\n",
        "        labels=labels,\n",
        "        input_ids_lens=input_ids_lens,\n",
        "        labels_lens=labels_lens,\n",
        "    )"
      ],
      "metadata": {
        "id": "y7e_TUxh5kC8"
      },
      "id": "y7e_TUxh5kC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(\n",
        "    sources: Sequence[str],\n",
        "    targets: Sequence[str],\n",
        "    tokenizer: transformers.PreTrainedTokenizer,\n",
        ") -> Dict:\n",
        "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
        "    examples = [s + t for s, t in zip(sources, targets)]\n",
        "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
        "    input_ids = examples_tokenized[\"input_ids\"]\n",
        "    labels = copy.deepcopy(input_ids)\n",
        "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
        "        label[:source_len] = IGNORE_INDEX\n",
        "    return dict(input_ids=input_ids, labels=labels)"
      ],
      "metadata": {
        "id": "kf6CXHm15kAO"
      },
      "id": "kf6CXHm15kAO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SupervisedDataset(Dataset):\n",
        "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
        "\n",
        "    def __init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer):\n",
        "        super(SupervisedDataset, self).__init__()\n",
        "        logging.warning(\"Loading data...\")\n",
        "        list_data_dict = json.load(open(data_path))\n",
        "\n",
        "        logging.warning(\"Formatting inputs...\")\n",
        "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
        "        sources = [\n",
        "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
        "            for example in list_data_dict\n",
        "        ]\n",
        "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
        "\n",
        "        logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
        "        data_dict = preprocess(sources, targets, tokenizer)\n",
        "\n",
        "        self.input_ids = data_dict[\"input_ids\"]\n",
        "        self.labels = data_dict[\"labels\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForSupervisedDataset(object):\n",
        "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
        "\n",
        "    tokenizer: transformers.PreTrainedTokenizer\n",
        "\n",
        "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
        "        )\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
        "        )"
      ],
      "metadata": {
        "id": "PUEFX7cVL8Vs"
      },
      "id": "PUEFX7cVL8Vs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/xglm-564M\"\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        max_length=100,\n",
        "        cache_dir=\"huggingface_cache\",\n",
        "    )\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    cache_dir=\"huggingface_cache\",\n",
        "    model_max_length=100,\n",
        "    padding_side=\"right\",\n",
        "    use_fast=False,\n",
        "    truncation=True\n",
        "    )"
      ],
      "metadata": {
        "id": "5Bu0dV2q7Hx3"
      },
      "id": "5Bu0dV2q7Hx3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = json.load(open('alpaca_cut_rus.json'))"
      ],
      "metadata": {
        "id": "Q60RnwwDlWsJ"
      },
      "id": "Q60RnwwDlWsJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(d, open('alpaca_c.json', 'w'),  indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "GebIPB7jldtF"
      },
      "id": "GebIPB7jldtF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=\"alpaca_cut_rus.json\", )\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "rN8vZ7pe7Hvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c312173f-574d-461d-879a-739b15b14ac6"
      },
      "id": "rN8vZ7pe7Hvd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Loading data...\n",
            "WARNING:root:Formatting inputs...\n",
            "WARNING:root:Tokenizing inputs... This may take some time...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=1,\n",
        "            collate_fn=data_collator,\n",
        "            shuffle=True,\n",
        "            drop_last=True,\n",
        "        )"
      ],
      "metadata": {
        "id": "T_h6W5hWm0Nc"
      },
      "id": "T_h6W5hWm0Nc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in dataloader:\n",
        "    break"
      ],
      "metadata": {
        "id": "qmVMhZK6m4H3"
      },
      "id": "qmVMhZK6m4H3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(b['input_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hLFZok1m7Wx",
        "outputId": "cee279b3-514a-40bc-b3d0-5884ede12d77"
      },
      "id": "6hLFZok1m7Wx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_args = transformers.TrainingArguments(learning_rate=1e-5, \n",
        "                 num_train_epochs=1,\n",
        "                 per_device_train_batch_size=5,\n",
        "                 gradient_accumulation_steps=1,\n",
        "                 evaluation_strategy='no',\n",
        "                 weight_decay=0.,\n",
        "                 warmup_ratio=0.03,\n",
        "                 lr_scheduler_type=\"cosine\",\n",
        "                 save_strategy='no',\n",
        "                 logging_steps=1000,\n",
        "                 output_dir=\"opt125_instruct_ft\",\n",
        "                 fp16=True)"
      ],
      "metadata": {
        "id": "RDyEvjrW7Hs6"
      },
      "id": "RDyEvjrW7Hs6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, \n",
        "                 tokenizer=tokenizer, \n",
        "                 args=train_args,\n",
        "                 train_dataset=train_dataset, \n",
        "                 eval_dataset=None, \n",
        "                 data_collator=data_collator)"
      ],
      "metadata": {
        "id": "EC-TTvT87Hqf"
      },
      "id": "EC-TTvT87Hqf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "I4PAwg_RL8TL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "ff432b06-5cec-4747-84b7-458cea43d83d"
      },
      "id": "I4PAwg_RL8TL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='1001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/1001 06:42, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.317300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1001, training_loss=3.316117494613617, metrics={'train_runtime': 405.932, 'train_samples_per_second': 12.322, 'train_steps_per_second': 2.466, 'total_flos': 902952830545920.0, 'train_loss': 3.316117494613617, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('xglm_ft_02')"
      ],
      "metadata": {
        "id": "_Gc6xnquL8Q0"
      },
      "id": "_Gc6xnquL8Q0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "SSgCceLoLsW8"
      },
      "id": "SSgCceLoLsW8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'xglm_ft_02'"
      ],
      "metadata": {
        "id": "2J7GQcK-LsUA"
      },
      "id": "2J7GQcK-LsUA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, model_max_length=512, max_length=512)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, max_length=512)"
      ],
      "metadata": {
        "id": "_CM7CGAuLsRJ"
      },
      "id": "_CM7CGAuLsRJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_for_instruction(instruction, text, model):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    prompt = (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "              \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "              f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{text}\\n\\n### Response:\")\n",
        "\n",
        "    inputs = tokenizer([prompt], \n",
        "                        return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    output_sequences = model.generate(\n",
        "        # this parameters are also important but you can read about them in the docs and just try changing them\n",
        "        num_beams=1,\n",
        "#         temperature=0.4,\n",
        "    #     max_length=100,\n",
        "        max_new_tokens=20,\n",
        "    #     no_repeat_ngram_size=4,\n",
        "    #     repetition_penalty= 5.0,\n",
        "    #     length_penalty=0.01,\n",
        "    #     early_stopping=True,\n",
        "    #     do_sample=True, \n",
        "    #     top_k=30, \n",
        "    #     top_p=0.8, \n",
        "        early_stopping=True,\n",
        "    #     num_return_sequences=3,\n",
        "        num_return_sequences= 1,\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        do_sample=False,  # disable sampling to test if batching affects output\n",
        "    )\n",
        "    summaries = tokenizer.batch_decode(output_sequences[:,len(inputs[0]):], skip_special_tokens=True)\n",
        "    return summaries[0]"
      ],
      "metadata": {
        "id": "Ae2W1vs5LsN3"
      },
      "id": "Ae2W1vs5LsN3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "«Ливерпуль» выбыл из борьбы за Джуда Беллингема. \n",
        "По данным The Telegraph, мерсисайдцы больше не планируют приобретать хавбека «Боруссии» Дортмунд из-за его цены. На трансфер ушло бы свыше 115 млн фунтов (без учета высокой зарплаты) – большая часть летнего бюджета. \n",
        "Вместо этого «Ливерпуль» сосредоточится на том, чтобы усилить каждую линию, требующую этого. Главный тренер Юрген Клопп поддерживает решение руководства. Немецкий специалист хочет, чтобы результаты работы по укреплению состава были видны как можно раньше, и потому менеджеры не хотят участвовать в длительной борьбе за игрока, который в итоге вообще может остаться в Бундеслиге еще на год. \n",
        "В числе претендентов на Беллингема называются «Манчестер Юнайтед», «Манчестер Сити», «ПСЖ», «Реал» и «Челси».\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gHKX8riyLsI_"
      },
      "id": "gHKX8riyLsI_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Перескажите содержание этого текста.\"\n",
        "predict_for_instruction(instruction, text, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Bs-ggHRqMGr4",
        "outputId": "3ba8b1d1-df1b-4a86-985f-c696184aa8dd"
      },
      "id": "Bs-ggHRqMGr4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ливерпуль выбыл из борьбы за Джуда Беллингема.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Напиши заголовок для текста.\"\n",
        "predict_for_instruction(instruction, text, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zU3R2DUUMGpe",
        "outputId": "d77e18a9-1802-417c-feee-66c8fe9883ed"
      },
      "id": "zU3R2DUUMGpe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ливерпуль выбыл из борьбы за Джуда Беллингема.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"\"\"\n",
        "Владельцев «Манчестер Юнайтед» не устроили заявки на приобретение клуба.\n",
        "Семья Глейзеров считает, что суммы полученных ими предложений недостаточно велики, сообщает журналист The Independent Мигель Дилэйни.\n",
        "Претендентам на покупку «Юнайтед» предложат улучшить заявки в третьем раунде переговоров, который пройдет в конце апреля.\n",
        "Ранее сообщалось, что Глейзеры хотят получить 6 миллиардов фунтов за продажу «Манчестер Юнайтед».\n",
        "Катарский шейх Джасим бин Хамад Аль Тани и владелец нефтяной компании INEOS англичанин Джим Рэтклифф предложили за клуб АПЛ около 5 миллиардов фунтов, финский бизнесмен и бывший топ-менеджер Nokia Томас Зиллиакус – меньше 4 млрд.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kojVkgqpNkQQ"
      },
      "id": "kojVkgqpNkQQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Напиши краткое содержание текста.\"\n",
        "predict_for_instruction(instruction, text_1, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AW02M1qoNkKO",
        "outputId": "6e91b305-e687-4ed5-b2cc-9c27e93768dd"
      },
      "id": "AW02M1qoNkKO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Семья Глейзеров считает, что суммы полученных ими предложений недостаточно велики.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Напиши заголовок для текста.\"\n",
        "predict_for_instruction(instruction, text_1, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U1y2JVZBNkAy",
        "outputId": "d267109d-a3f9-49cc-b4c7-dd9ccffea72b"
      },
      "id": "U1y2JVZBNkAy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Семья Глейзеров считает, что суммы полученных ими предложений недостаточно велики.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если как-то видоизменять запросы, оставаясь в контексте суммаризации и \"осмысления\" материала, то модель даст такие же ответы, как и выше. Я пробовала другие тексты и видела варианты ответов, больше похожие именно на суммаризацию и с бОльшим \"творчеством\", но то, что есть выше, как-то покрасивее.\n",
        "\n",
        "Мне не очень нравится такое однообразие ответов. Но, во-первых, с ними не поспоришь, они более чем адекватные. Во-вторых, есть подозрение, что 5000 инструкций - маловато для более качественной работы с текстом. Все же для оригинальной alpaca инструкций было в разы больше, и как знать, может быть многое, подходящее для работы с текстом, не попало в мою выборку. "
      ],
      "metadata": {
        "id": "GQcpI7MYhyWT"
      },
      "id": "GQcpI7MYhyWT"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}